{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/rev_sentiment_gold.pkl', 'rb') as f:\n",
    "    rev_sentiment_dict = pickle.load(f)\n",
    "\n",
    "with open('data/sentiment_gold.pkl', 'rb') as f:\n",
    "    sentiment_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sentiment_subject_data_new.pkl', 'rb') as f:\n",
    "    subjects_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = ['ZAB', 'ZDM', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH','ZKW', 'ZMG', 'ZPH', 'ZDN']\n",
    "sentence_level_feats = [\"sent_mean\", \"sm_a1\", \"sm_a2\", \"sm_b1\", \"sm_b2\", \"sm_g1\", \"sm_g2\", \"sm_t1\", \"sm_t2\"]\n",
    "word_level_feats = [\"word_mean\", \"FFD\", \"TRT\", \"GD\", \"GPT\", \"SFD\", \"wm_a1\", \"wm_a2\", \"wm_b1\", \"wm_b2\", \"wm_g1\", \"wm_g2\", \n",
    "                    \"wm_t1\", \"wm_t2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4675"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(subjects_data[i]) for i in subject_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_feats = [\"sm_a1\", \"sm_a2\", \"sm_b1\", \"sm_b2\", \"sm_g1\", \"sm_g2\", \"sm_t1\", \"sm_t2\"]\n",
    "\n",
    "def create_sentence_level_feature_df():\n",
    "    df = pd.DataFrame(columns=[\"sm_\"+str(x) for x in range(1,106)])\n",
    "    \n",
    "    xtlist = []\n",
    "    ytlist = []\n",
    "    \n",
    "    for subid in subject_ids:\n",
    "        for sentid in subjects_data[subid]:\n",
    "#             try:\n",
    "            new_vec = []\n",
    "            for fqfeat in freq_feats:\n",
    "                arr = subjects_data[subid][sentid][fqfeat]\n",
    "                where_are_NaNs = np.isnan(arr)\n",
    "                arr[where_are_NaNs] = 0\n",
    "                new_vec = new_vec + list(arr)\n",
    "#             xtlist.append([subid+sentid]+new_vec)\n",
    "            xtlist.append(new_vec)\n",
    "            ytlist.append(sentiment_dict[sentid]['label'])\n",
    "#             except Exception as ex:\n",
    "#                 print(sentid, subid, ex)\n",
    "    return xtlist, ytlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt, yt = create_sentence_level_feature_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca100 = PCA(n_components=100, svd_solver='auto')\n",
    "X100 = pca100.fit_transform(np.array(Xt))\n",
    "\n",
    "pca200 = PCA(n_components=200, svd_solver='auto')\n",
    "X200 = pca200.fit_transform(np.array(Xt))\n",
    "\n",
    "pca300 = PCA(n_components=300, svd_solver='auto')\n",
    "X300 = pca300.fit_transform(np.array(Xt))\n",
    "\n",
    "pca500 = PCA(n_components=500, svd_solver='auto')\n",
    "X500 = pca500.fit_transform(np.array(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4675, 840), (4675, 100))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xt), np.shape(X100), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xtt in [X100, X200, X300, X500]:\n",
    "#     MX = pd.DataFrame(xtt)\n",
    "#     my = pd.DataFrame(yt)\n",
    "\n",
    "#     # X = X.rename(columns={0: 'UID'})\n",
    "#     my = my.rename(columns={0: 'label'})\n",
    "\n",
    "#     print(MX.shape)\n",
    "#     print(my.shape)\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(MX, my, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4515, 106)\n",
      "(4515, 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing & results----------------\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# nlp preprocessing\n",
    "import spacy\n",
    "\n",
    "# Models-------------------------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "import sklearn.gaussian_process.kernels as kls\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "\n",
    "# for visualizing ---------------\n",
    "from sklearn import tree\n",
    "from six import StringIO \n",
    "from IPython.display import Image, display\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# General purpose\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dict = {\n",
    "    'DecisionTree': {\"model\": DecisionTreeClassifier(random_state=42), \"params\": {'max_depth': list(range(10, 250, 20))}},\n",
    "    'RandomForest': {\"model\": RandomForestClassifier(random_state=42),\n",
    "                     \"params\": {'n_estimators': list(range(5, 100, 5)), 'max_depth': list(range(10, 250, 20))}},\n",
    "    'LogisticR_L1': {\"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "                     \"params\": {'penalty': ['l1'], 'solver': ['liblinear', 'saga']}},\n",
    "    'LogisticR_L2': {\"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "                     \"params\": {'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}},\n",
    "    'LogisticR': {\"model\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "                  \"params\": {'penalty': ['none'], 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}},\n",
    "    'RidgeClf': {\"model\": RidgeClassifier(max_iter=1000), \"params\": {}},\n",
    "    'SVC_linear': {\"model\": SVC(random_state=42), \"params\": {'kernel': ['linear'], \n",
    "                                                             'C': [0.5, 1.0, 1.5, 2.0, 2.5]}},\n",
    "    'SVC_poly': {\"model\": SVC(random_state=42),\n",
    "                 \"params\": {'kernel': ['poly'], 'degree': [3, 4, 5], 'gamma': ['scale', 'auto'], \n",
    "                            'C': [0.5, 1.0, 1.5, 2.0, 2.5]}},\n",
    "    'SVC_others': {\"model\": SVC(random_state=42), \"params\": {'kernel': ['rbf', 'sigmoid'], \n",
    "                                                             'gamma': ['scale', 'auto'], \n",
    "                                                             'C': [0.5, 1.0, 1.5, 2.0, 2.5]}},\n",
    "    'GussianNB': {\"model\": GaussianNB(), \"params\": {}},\n",
    "    'KNN': {\"model\": KNeighborsClassifier(), \"params\": {'n_neighbors': list(range(1, 20))}},\n",
    "    'GaussianProcessClf': {\"model\": GaussianProcessClassifier(random_state=42, kernel=kls.RBF()), \"params\": {}},\n",
    "    'Bagging_SVC': {\"model\": BaggingClassifier(random_state=42), \"params\": {'n_estimators': list(range(5, 100, 5)),\n",
    "                                                                            'base_estimator': [SVC(kernel='linear'),\n",
    "                                                                                               SVC(kernel='poly',\n",
    "                                                                                                   degree=3,\n",
    "                                                                                                   gamma='scale')]}},\n",
    "    'BaggingDT': {\"model\": BaggingClassifier(random_state=42), \"params\": {'n_estimators': list(range(5, 100, 5)),\n",
    "                                                                          'base_estimator': [\n",
    "                                                                              DecisionTreeClassifier(random_state=42,\n",
    "                                                                                                     max_depth=10),\n",
    "                                                                              DecisionTreeClassifier(random_state=42,\n",
    "                                                                                                     max_depth=50),\n",
    "                                                                              DecisionTreeClassifier(random_state=42,\n",
    "                                                                                                     max_depth=100)]}},\n",
    "    'AdaBoost': {\"model\": AdaBoostClassifier(random_state=42), \"params\": {'n_estimators': list(range(5, 100, 5)),\n",
    "                                                                          'base_estimator': [DecisionTreeClassifier(\n",
    "                                                                                                 random_state=42,\n",
    "                                                                                                 max_depth=10),\n",
    "                                                                                             DecisionTreeClassifier(\n",
    "                                                                                                 random_state=42,\n",
    "                                                                                                 max_depth=50),\n",
    "                                                                                             DecisionTreeClassifier(\n",
    "                                                                                                 random_state=42,\n",
    "                                                                                                 max_depth=100)]}},\n",
    "    'ExtraTrees': {\"model\": ExtraTreesClassifier(random_state=42), \"params\": {'n_estimators': list(range(5, 105, 5)), \n",
    "                                                                              'max_depth': [10, 50, 100, 250, 400]}},\n",
    "    'MLP_l1': {\"model\": MLPClassifier(random_state=42), \"params\": {'hidden_layer_sizes': [(x,) for x in \n",
    "                                                                                          range(50, 600, 100)], \n",
    "                                                                  'activation': ['logistic', 'tanh', 'relu'],\n",
    "                                                                  'solver': ['adam', 'sgd'], 'early_stopping': \n",
    "                                                                   [True]}},\n",
    "    'MLP_l2': {\"model\": MLPClassifier(random_state=42), \"params\": {'hidden_layer_sizes': [(x, y) for x in \n",
    "                                                                                          range(50, 600, 100) \n",
    "                                                                                          for y in range(50, 360, 100)], \n",
    "                                                                  'activation': ['logistic', 'tanh', 'relu'],\n",
    "                                                                  'solver': ['adam', 'sgd'], 'early_stopping': \n",
    "                                                                                               [True]}},\n",
    "    'MLP_l3': {\"model\": MLPClassifier(random_state=42), \"params\": {'hidden_layer_sizes': [(x, y, z) for x in \n",
    "                                                                                          range(50, 600, 100) \n",
    "                                                                                          for y in range(50, 600, 100)\n",
    "                                                                                          for z in range(50, 360, 100)], \n",
    "                                                                  'activation': ['logistic', 'tanh', 'relu'],\n",
    "                                                                  'solver': ['adam', 'sgd'], 'early_stopping': \n",
    "                                                                                               [True]}},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4675, 100)\n",
      "(4675, 1)\n",
      "=================================================================================\n",
      "=================================================================================\n",
      "DecisionTree 0.29990427098151967 0.3462566844919786 {'max_depth': 10}\n",
      "RandomForest 0.34822584585078853 0.36711229946524065 {'max_depth': 10, 'n_estimators': 30}\n",
      "LogisticR_L1 0.3331653061459124 0.33475935828877007 {'penalty': 'l1', 'solver': 'liblinear'}\n",
      "LogisticR_L2 0.3293207583478524 0.33502673796791443 {'penalty': 'l2', 'solver': 'saga'}\n",
      "LogisticR 0.33080186442523385 0.33449197860962565 {'penalty': 'none', 'solver': 'saga'}\n",
      "RidgeClf 0.33179230736745474 0.3358288770053476 {}\n",
      "SVC_linear 0.34992774080795863 0.33636363636363636 {'C': 1.5, 'kernel': 'linear'}\n",
      "SVC_poly 0.22648000292588052 0.34946524064171125 {'C': 0.5, 'degree': 5, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "SVC_others 0.28368712301738425 0.3548128342245989 {'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "GussianNB 0.3121435538272275 0.3323529411764706 {}\n",
      "KNN 0.35944723793561 0.3352941176470588 {'n_neighbors': 13}\n",
      "GaussianProcessClf 0.1699867197875166 0.3518716577540107 {}\n"
     ]
    }
   ],
   "source": [
    "for xtt in [X100]:#, X200, X300, X500]:\n",
    "    MX = pd.DataFrame(xtt)\n",
    "    my = pd.DataFrame(yt)\n",
    "\n",
    "    # X = X.rename(columns={0: 'UID'})\n",
    "    my = my.rename(columns={0: 'label'})\n",
    "\n",
    "    print(MX.shape)\n",
    "    print(my.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(MX, my, test_size=0.20, random_state=42)\n",
    "    print(\"=================================================================================\")\n",
    "    print(\"=================================================================================\")\n",
    "    \n",
    "    model_results = pd.DataFrame()\n",
    "    model_results['Train_Accuracy'] = None\n",
    "    model_results['Test_Accuracy'] = None\n",
    "    model_results['best_params'] = None\n",
    "\n",
    "    # X_train, X_test, y_train, y_test\n",
    "    # X_train_final = X_train_normalized.drop(columns=[\"ref_latest\"])\n",
    "    # X_test_normalized_remgsdata = X_test_normalized.drop(columns=[\"ref_latest\"])\n",
    "    # X_train_normalized_remgsdata = X_train_normalized.copy()\n",
    "    # X_test_normalized_remgsdata = X_test_normalized.copy()\n",
    "\n",
    "    xtrain_final = X_train#.drop(columns=[\"UID\"])\n",
    "    ytrain_final = y_train\n",
    "    # ytrain_final = ytrain.drop(columns=[\"UID\"])\n",
    "\n",
    "    xtest_final = X_test#.drop(columns=[\"UID\"])\n",
    "    ytest_final = y_test\n",
    "    # ytest_final = ytest.drop(columns=[\"UID\"])\n",
    "\n",
    "\n",
    "    best_clf_ours = None\n",
    "    best_clf_val = 0\n",
    "\n",
    "    for clf_name, clf in clf_dict.items():\n",
    "        classifier = GridSearchCV(clf['model'], clf['params'], n_jobs=5)\n",
    "        classifier.fit(xtrain_final, ytrain_final)\n",
    "        best_model = classifier.best_estimator_\n",
    "        \n",
    "\n",
    "        y_predicted = best_model.predict(xtest_final)\n",
    "        test_acc_macro = precision_recall_fscore_support(ytest_final, y_predicted, average='macro')[2]#accuracy_score(ytest_final, y_predicted)\n",
    "        print(clf_name, test_acc_macro, classifier.best_score_, classifier.best_params_)\n",
    "\n",
    "        if test_acc_macro > best_clf_val:\n",
    "            best_clf_val = test_acc_macro\n",
    "            best_clf_ours = best_model\n",
    "\n",
    "        model_results.loc[clf_name, ['Train_Accuracy', 'Test_Accuracy', 'best_params']] = [classifier.best_score_, test_acc_macro, classifier.best_params_]\n",
    "        clsr = classification_report(ytest_final, y_predicted)\n",
    "\n",
    "    print(\"================================================================================\")\n",
    "    print(best_clf_ours)\n",
    "    best_y_hat = best_clf_ours.predict(xtest_final)\n",
    "    clsr = classification_report(ytest_final, best_y_hat)\n",
    "    print(clsr)\n",
    "    test_acc = accuracy_score(ytest_final, best_y_hat)\n",
    "    print(\"Test acc:\", test_acc )\n",
    "    print(\"Weighted F1 score: \", f1_score(ytest_final, best_y_hat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_results = pd.DataFrame()\n",
    "# model_results['Train_Accuracy'] = None\n",
    "# model_results['Test_Accuracy'] = None\n",
    "# model_results['best_params'] = None\n",
    "\n",
    "# # X_train, X_test, y_train, y_test\n",
    "# # X_train_final = X_train_normalized.drop(columns=[\"ref_latest\"])\n",
    "# # X_test_normalized_remgsdata = X_test_normalized.drop(columns=[\"ref_latest\"])\n",
    "# # X_train_normalized_remgsdata = X_train_normalized.copy()\n",
    "# # X_test_normalized_remgsdata = X_test_normalized.copy()\n",
    "\n",
    "# xtrain_final = X_train.drop(columns=[\"UID\"])\n",
    "# ytrain_final = y_train\n",
    "# # ytrain_final = ytrain.drop(columns=[\"UID\"])\n",
    "\n",
    "# xtest_final = X_test.drop(columns=[\"UID\"])\n",
    "# ytest_final = y_test\n",
    "# # ytest_final = ytest.drop(columns=[\"UID\"])\n",
    "\n",
    "\n",
    "# best_clf_ours = None\n",
    "# best_clf_val = 0\n",
    "\n",
    "# for clf_name, clf in clf_dict.items():\n",
    "#     classifier = GridSearchCV(clf['model'], clf['params'], n_jobs=5)\n",
    "#     classifier.fit(xtrain_final, ytrain_final)\n",
    "#     best_model = classifier.best_estimator_\n",
    "#     print(clf_name, classifier.best_score_, classifier.best_params_)\n",
    "    \n",
    "#     y_predicted = best_model.predict(xtest_final)\n",
    "#     test_acc_macro = precision_recall_fscore_support(ytest_final, y_predicted, average='macro')[2]#accuracy_score(ytest_final, y_predicted)\n",
    "    \n",
    "#     if test_acc_macro > best_clf_val:\n",
    "#         best_clf_val = test_acc_macro\n",
    "#         best_clf_ours = best_model\n",
    "    \n",
    "#     model_results.loc[clf_name, ['Train_Accuracy', 'Test_Accuracy', 'best_params']] = [classifier.best_score_, test_acc_macro, classifier.best_params_]\n",
    "#     clsr = classification_report(ytest_final, y_predicted)\n",
    "\n",
    "# print(\"================================================================================\")\n",
    "# print(best_clf_ours)\n",
    "# best_y_hat = best_clf_ours.predict(xtest_final)\n",
    "# clsr = classification_report(ytest_final, best_y_hat)\n",
    "# print(clsr)\n",
    "# test_acc = accuracy_score(ytest_final, best_y_hat)\n",
    "# print(\"Test acc:\", test_acc )\n",
    "# print(\"Weighted F1 score: \", f1_score(ytest_final, best_y_hat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.346257</td>\n",
       "      <td>0.299904</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.367112</td>\n",
       "      <td>0.348226</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR_L1</th>\n",
       "      <td>0.334759</td>\n",
       "      <td>0.333165</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR_L2</th>\n",
       "      <td>0.335027</td>\n",
       "      <td>0.329321</td>\n",
       "      <td>{'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticR</th>\n",
       "      <td>0.334492</td>\n",
       "      <td>0.330802</td>\n",
       "      <td>{'penalty': 'none', 'solver': 'saga'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClf</th>\n",
       "      <td>0.335829</td>\n",
       "      <td>0.331792</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_linear</th>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.349928</td>\n",
       "      <td>{'C': 1.5, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_poly</th>\n",
       "      <td>0.349465</td>\n",
       "      <td>0.22648</td>\n",
       "      <td>{'C': 0.5, 'degree': 5, 'gamma': 'scale', 'ker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_others</th>\n",
       "      <td>0.354813</td>\n",
       "      <td>0.283687</td>\n",
       "      <td>{'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GussianNB</th>\n",
       "      <td>0.332353</td>\n",
       "      <td>0.312144</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.335294</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessClf</th>\n",
       "      <td>0.351872</td>\n",
       "      <td>0.169987</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Train_Accuracy Test_Accuracy  \\\n",
       "DecisionTree             0.346257      0.299904   \n",
       "RandomForest             0.367112      0.348226   \n",
       "LogisticR_L1             0.334759      0.333165   \n",
       "LogisticR_L2             0.335027      0.329321   \n",
       "LogisticR                0.334492      0.330802   \n",
       "RidgeClf                 0.335829      0.331792   \n",
       "SVC_linear               0.336364      0.349928   \n",
       "SVC_poly                 0.349465       0.22648   \n",
       "SVC_others               0.354813      0.283687   \n",
       "GussianNB                0.332353      0.312144   \n",
       "KNN                      0.335294      0.359447   \n",
       "GaussianProcessClf       0.351872      0.169987   \n",
       "\n",
       "                                                          best_params  \n",
       "DecisionTree                                        {'max_depth': 10}  \n",
       "RandomForest                    {'max_depth': 10, 'n_estimators': 30}  \n",
       "LogisticR_L1                 {'penalty': 'l1', 'solver': 'liblinear'}  \n",
       "LogisticR_L2                      {'penalty': 'l2', 'solver': 'saga'}  \n",
       "LogisticR                       {'penalty': 'none', 'solver': 'saga'}  \n",
       "RidgeClf                                                           {}  \n",
       "SVC_linear                             {'C': 1.5, 'kernel': 'linear'}  \n",
       "SVC_poly            {'C': 0.5, 'degree': 5, 'gamma': 'scale', 'ker...  \n",
       "SVC_others              {'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'}  \n",
       "GussianNB                                                          {}  \n",
       "KNN                                               {'n_neighbors': 13}  \n",
       "GaussianProcessClf                                                 {}  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN - 36.8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
