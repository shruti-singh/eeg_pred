{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_ZuCo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/home/singh_shruti/ZuCo_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_dir = dataset_dir + \"task1_sr/Matlab files/\"\n",
    "task2_dir = dataset_dir + \"task2_nr/Matlab files/\"\n",
    "task3_dir = dataset_dir + \"task3_tsr/Matlab files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['ZAB', 'ZDM', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH','ZKW', 'ZMG', 'ZPH', 'ZDN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = defaultdict(int)\n",
    "sentences_dict = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/rev_sentiment_gold.pkl', 'rb') as f:\n",
    "    rev_sentiment_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:  ['resultsZDN_SR.mat', 'resultsZKH_SR.mat', 'resultsZKB_SR.mat', 'resultsZJN_SR.mat', 'resultsZDM_SR.mat', 'resultsZKW_SR.mat', 'resultsZPH_SR.mat', 'resultsZMG_SR.mat', 'resultsZAB_SR.mat', 'resultsZJM_SR.mat', 'resultsZJS_SR.mat', 'resultsZGW_SR.mat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZDN - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZDN - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "'float' object is not iterable\n",
      "ZKH - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZKH - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZKB - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZKB - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZJN - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZJN - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZDM - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZDM - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZKW - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZKW - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZPH - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZPH - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZMG - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZMG - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZAB - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZAB - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZJM - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZJM - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZJS - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZJS - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n",
      "ZGW - Sent not found: Ultimately feels emp11111ty and unsatisfying, like swallowing a Communion wafer without the wine.\n",
      "ZGW - Sent not found: Bullock's complete lack of focus and ability quickly derails the film.1\n"
     ]
    }
   ],
   "source": [
    "taskfile_paths = [task1_dir, task2_dir, task3_dir]\n",
    "subjects_data = {}\n",
    "\n",
    "sentence_level_feats = [\"sent_mean\", \"sm_a1\", \"sm_a2\", \"sm_b1\", \"sm_b2\", \"sm_g1\", \"sm_g2\", \"sm_t1\", \"sm_t2\"]\n",
    "word_level_feats = [\"word_mean\", \"FFD\", \"TRT\", \"GD\", \"GPT\", \"SFD\", \"wm_a1\", \"wm_a2\", \"wm_b1\", \"wm_b2\", \"wm_g1\", \"wm_g2\", \n",
    "                    \"wm_t1\", \"wm_t2\"]\n",
    "\n",
    "# First experiment with only the first task (sentiment analysis) data\n",
    "for path in taskfile_paths[0:1]:\n",
    "    print(\"Files: \", os.listdir(path))\n",
    "    mat_files = [os.path.join(path,file) for file in os.listdir(path)]\n",
    "    \n",
    "    for filepath in mat_files:\n",
    "        subject_id = filepath[-10:-7]  # Is of form '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZDN_SR.mat'\n",
    "        subjects_data[subject_id] = {}\n",
    "        \n",
    "        data = io.loadmat(filepath, squeeze_me=True, struct_as_record=False)['sentenceData']\n",
    "\n",
    "        for sent_item in data:\n",
    "            #print(data[0].content)\n",
    "            prc_sent = sent_item.content.strip()\n",
    "            sentences_dict[prc_sent] += 1\n",
    "            if prc_sent in rev_sentiment_dict:\n",
    "                sentid = rev_sentiment_dict[prc_sent]['id']\n",
    "                sent_mean_vec = []\n",
    "                \n",
    "#                 if np.all(np.isnan(sent_item.word)):\n",
    "#                     continue\n",
    "                \n",
    "                subjects_data[subject_id][sentid] = {k: None for k in sentence_level_feats}\n",
    "                if 'mean_a1' in sent_item.__dict__ and not np.any(np.isnan(sent_item.__dict__['mean_a1'])) and np.shape(sent_item.__dict__['mean_a1'])[0] != 0:\n",
    "                    subjects_data[subject_id][sentid][\"sm_a1\"] = sent_item.__dict__['mean_a1']\n",
    "                    sent_mean_vec.append(sent_item.__dict__['mean_a1'])\n",
    "                else:\n",
    "                    subjects_data[subject_id][sentid][\"sm_a1\"] = np.zeros(105, )\n",
    "                \n",
    "                if 'mean_a2' in sent_item.__dict__ and not np.any(np.isnan(sent_item.__dict__['mean_a2'])) and np.shape(sent_item.__dict__['mean_a2'])[0] != 0:\n",
    "                    subjects_data[subject_id][sentid][\"sm_a2\"] = sent_item.__dict__['mean_a2']\n",
    "                    sent_mean_vec.append(sent_item.__dict__['mean_a2'])\n",
    "                else:\n",
    "                    subjects_data[subject_id][sentid][\"sm_a2\"] =  np.zeros(105, )\n",
    "                \n",
    "                if 'mean_b1' in sent_item.__dict__ and not np.any(np.isnan(sent_item.__dict__['mean_b1'])) and np.shape(sent_item.__dict__['mean_b1'])[0] != 0:\n",
    "                    subjects_data[subject_id][sentid][\"sm_b1\"] = sent_item.__dict__['mean_b1'] \n",
    "                    sent_mean_vec.append(subjects_data[subject_id][sentid][\"sm_b1\"])\n",
    "                else:\n",
    "                    subjects_data[subject_id][sentid][\"sm_b1\"] = np.zeros(105, )\n",
    "                \n",
    "                if 'mean_b2' in sent_item.__dict__ and not np.any(np.isnan(sent_item.__dict__['mean_b2'])) and np.shape(sent_item.__dict__['mean_b2'])[0] != 0:\n",
    "                    subjects_data[subject_id][sentid][\"sm_b2\"] = sent_item.__dict__['mean_b2'] \n",
    "                    sent_mean_vec.append(sent_item.__dict__['mean_b2'])\n",
    "                else:\n",
    "                    subjects_data[subject_id][sentid][\"sm_b2\"] =  np.zeros(105, )\n",
    "                \n",
    "                if 'mean_g1' in sent_item.__dict__ and not np.any(np.isnan(sent_item.__dict__['mean_g1'])) and np.shape(sent_item.__dict__['mean_g1'])[0] != 0:\n",
    "                    subjects_data[subject_id][sentid][\"sm_g1\"] = sent_item.__dict__['mean_g1']\n",
    "                    sent_mean_vec.append(sent_item.__dict__['mean_g1'])\n",
    "                else:\n",
    "                    subjects_data[subject_id][sentid][\"sm_g1\"] = np.zeros(105, )\n",
    "                \n",
    "                if 'mean_g2' in sent_item.__dict__ and not np.any(np.isnan(sent_item.__dict__['mean_g2'])) and np.shape(sent_item.__dict__['mean_g2'])[0] != 0:\n",
    "                    subjects_data[subject_id][sentid][\"sm_g2\"] = sent_item.__dict__['mean_g2']\n",
    "                    sent_mean_vec.append(sent_item.__dict__['mean_g2'])\n",
    "                else:\n",
    "                    subjects_data[subject_id][sentid][\"sm_g2\"] =  np.zeros(105, )\n",
    "                \n",
    "                if 'mean_t1' in sent_item.__dict__ and not np.any(np.isnan(sent_item.__dict__['mean_t1'])) and np.shape(sent_item.__dict__['mean_t1'])[0] != 0:\n",
    "                    subjects_data[subject_id][sentid][\"sm_t1\"] = sent_item.__dict__['mean_t1'] \n",
    "                    sent_mean_vec.append(subjects_data[subject_id][sentid][\"sm_t1\"])\n",
    "                else:\n",
    "                    subjects_data[subject_id][sentid][\"sm_t1\"] = np.zeros(105, )\n",
    "                \n",
    "                if 'mean_t2' in sent_item.__dict__ and not np.any(np.isnan(sent_item.__dict__['mean_t2'])) and np.shape(sent_item.__dict__['mean_t2'])[0] != 0:\n",
    "                    subjects_data[subject_id][sentid][\"sm_t2\"] = sent_item.__dict__['mean_t2'] \n",
    "                    sent_mean_vec.append(sent_item.__dict__['mean_t2'])\n",
    "                else:\n",
    "                    subjects_data[subject_id][sentid][\"sm_t2\"] =  np.zeros(105, )\n",
    "                subjects_data[subject_id][sentid][\"sent_mean\"] = np.mean(sent_mean_vec, axis=0)\n",
    "                sent_mean_vec = []\n",
    "                \n",
    "                try:\n",
    "                    # Process words data now\n",
    "                    subjects_data[subject_id][sentid][\"words\"] = {}\n",
    "                    subjects_data[subject_id][sentid][\"words_list\"] = []\n",
    "                    word_counter = 0\n",
    "                    inside_loop = False\n",
    "                    for w_item in sent_item.word:\n",
    "                        inside_loop = True\n",
    "                        prc_word = w_item.content.strip().lower()\n",
    "                        words_dict[prc_word] += 1\n",
    "                        subjects_data[subject_id][sentid][\"words_list\"].append(w_item.content.strip())\n",
    "                        subjects_data[subject_id][sentid][\"words\"][word_counter] = {k: None for k in word_level_feats}\n",
    "\n",
    "                        word_mean_vec = []\n",
    "                        for feat in [\"FFD\", \"TRT\", \"GD\", \"GPT\", \"SFD\"]:\n",
    "                            if feat in w_item.__dict__ and np.shape(w_item.__dict__[feat]) != 0:\n",
    "                                subjects_data[subject_id][sentid][\"words\"][word_counter][feat] = w_item.__dict__[feat]\n",
    "                                word_mean_vec.append(w_item.__dict__[feat])\n",
    "                            else:\n",
    "                                subjects_data[subject_id][sentid][\"words\"][word_counter][feat] = np.zeros(105, )\n",
    "                        subjects_data[subject_id][sentid][\"words\"][word_counter][\"word_mean\"] = np.mean(word_mean_vec, axis=0)\n",
    "                        word_mean_vec = []\n",
    "\n",
    "                        for f1 in [\"_a1\", \"_a2\", \"_b1\", \"_b2\", \"_g1\", \"_g2\", \"_t1\", \"_t2\"]:\n",
    "                            f1_mean_vec = []\n",
    "                            for f2 in [\"FFD\", \"TRT\", \"GD\", \"GPT\", \"SFD\"]:\n",
    "                                composite_key = f2 + f1\n",
    "                                if composite_key in w_item.__dict__ and np.shape(w_item.__dict__[composite_key])[0] != 0:\n",
    "                                    f1_mean_vec.append(w_item.__dict__[composite_key])\n",
    "                            if len(f1_mean_vec) > 0:\n",
    "                                subjects_data[subject_id][sentid][\"words\"][word_counter][\"wm\" + f1] = np.mean(f1_mean_vec, axis=0)\n",
    "                            else:\n",
    "                                subjects_data[subject_id][sentid][\"words\"][word_counter][\"wm\" + f1] = np.zeros(105, )\n",
    "                        word_counter += 1\n",
    "                except Exception as ex:\n",
    "                    if not inside_loop:\n",
    "                        subjects_data[subject_id].pop(sentid)\n",
    "                    print(ex)\n",
    "#                     print(sent_item)\n",
    "#                     print(prc_sent, sentid, w_item, ex)\n",
    "            else:\n",
    "                print(\"{} - Sent not found: {}\".format(subject_id, prc_sent))\n",
    "            \n",
    "            # stop at one sentence (total 400)\n",
    "            # break\n",
    "        \n",
    "        # stop at one subject (total 12)\n",
    "        # break\n",
    "    \n",
    "    # stop at the first task (total 3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sentiment_subject_data_new.pkl', 'wb') as f:\n",
    "    pickle.dump(subjects_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 4616)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*12, sum(len(subjects_data[i]) for i in subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 4675)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*12, sum(len(subjects_data[i]) for i in subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjects_data[subject_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Martyr gets royally screwed and comes back for more.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_item.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_item.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-8dc7930ef42a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_a1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nan' is not defined"
     ]
    }
   ],
   "source": [
    "sent_item.__dict__['mean_a1'] == nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZDN'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZDN_SR.mat'[-10:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_fieldnames',\n",
       " 'allFixations',\n",
       " 'answer_mean_a1',\n",
       " 'answer_mean_a1_diff',\n",
       " 'answer_mean_a2',\n",
       " 'answer_mean_a2_diff',\n",
       " 'answer_mean_b1',\n",
       " 'answer_mean_b1_diff',\n",
       " 'answer_mean_b2',\n",
       " 'answer_mean_b2_diff',\n",
       " 'answer_mean_g1',\n",
       " 'answer_mean_g1_diff',\n",
       " 'answer_mean_g2',\n",
       " 'answer_mean_g2_diff',\n",
       " 'answer_mean_t1',\n",
       " 'answer_mean_t1_diff',\n",
       " 'answer_mean_t2',\n",
       " 'answer_mean_t2_diff',\n",
       " 'content',\n",
       " 'mean_a1',\n",
       " 'mean_a1_diff',\n",
       " 'mean_a1_diff_sec',\n",
       " 'mean_a1_sec',\n",
       " 'mean_a2',\n",
       " 'mean_a2_diff',\n",
       " 'mean_a2_diff_sec',\n",
       " 'mean_a2_sec',\n",
       " 'mean_b1',\n",
       " 'mean_b1_diff',\n",
       " 'mean_b1_diff_sec',\n",
       " 'mean_b1_sec',\n",
       " 'mean_b2',\n",
       " 'mean_b2_diff',\n",
       " 'mean_b2_diff_sec',\n",
       " 'mean_b2_sec',\n",
       " 'mean_g1',\n",
       " 'mean_g1_diff',\n",
       " 'mean_g1_diff_sec',\n",
       " 'mean_g1_sec',\n",
       " 'mean_g2',\n",
       " 'mean_g2_diff',\n",
       " 'mean_g2_diff_sec',\n",
       " 'mean_g2_sec',\n",
       " 'mean_t1',\n",
       " 'mean_t1_diff',\n",
       " 'mean_t1_diff_sec',\n",
       " 'mean_t1_sec',\n",
       " 'mean_t2',\n",
       " 'mean_t2_diff',\n",
       " 'mean_t2_diff_sec',\n",
       " 'mean_t2_sec',\n",
       " 'omissionRate',\n",
       " 'rawData',\n",
       " 'word',\n",
       " 'wordbounds']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sent_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of sentences datastructure\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_fieldnames',\n",
       " 'allFixations',\n",
       " 'answer_mean_a1',\n",
       " 'answer_mean_a1_diff',\n",
       " 'answer_mean_a2',\n",
       " 'answer_mean_a2_diff',\n",
       " 'answer_mean_b1',\n",
       " 'answer_mean_b1_diff',\n",
       " 'answer_mean_b2',\n",
       " 'answer_mean_b2_diff',\n",
       " 'answer_mean_g1',\n",
       " 'answer_mean_g1_diff',\n",
       " 'answer_mean_g2',\n",
       " 'answer_mean_g2_diff',\n",
       " 'answer_mean_t1',\n",
       " 'answer_mean_t1_diff',\n",
       " 'answer_mean_t2',\n",
       " 'answer_mean_t2_diff',\n",
       " 'content',\n",
       " 'mean_a1',\n",
       " 'mean_a1_diff',\n",
       " 'mean_a1_diff_sec',\n",
       " 'mean_a1_sec',\n",
       " 'mean_a2',\n",
       " 'mean_a2_diff',\n",
       " 'mean_a2_diff_sec',\n",
       " 'mean_a2_sec',\n",
       " 'mean_b1',\n",
       " 'mean_b1_diff',\n",
       " 'mean_b1_diff_sec',\n",
       " 'mean_b1_sec',\n",
       " 'mean_b2',\n",
       " 'mean_b2_diff',\n",
       " 'mean_b2_diff_sec',\n",
       " 'mean_b2_sec',\n",
       " 'mean_g1',\n",
       " 'mean_g1_diff',\n",
       " 'mean_g1_diff_sec',\n",
       " 'mean_g1_sec',\n",
       " 'mean_g2',\n",
       " 'mean_g2_diff',\n",
       " 'mean_g2_diff_sec',\n",
       " 'mean_g2_sec',\n",
       " 'mean_t1',\n",
       " 'mean_t1_diff',\n",
       " 'mean_t1_diff_sec',\n",
       " 'mean_t1_sec',\n",
       " 'mean_t2',\n",
       " 'mean_t2_diff',\n",
       " 'mean_t2_diff_sec',\n",
       " 'mean_t2_sec',\n",
       " 'omissionRate',\n",
       " 'rawData',\n",
       " 'word',\n",
       " 'wordbounds']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7034963 , 0.6258178 , 0.8860085 , 0.7699399 , 0.7714355 ,\n",
       "       0.5110524 , 0.52470464, 0.69962174, 0.93221384, 0.90646076,\n",
       "       0.8137055 , 0.55650216, 0.6928516 , 0.6534393 , 0.8337521 ,\n",
       "       1.0126307 , 0.48507643, 0.6197668 , 0.7751927 , 0.54318595,\n",
       "       0.7491286 , 0.91322684, 0.8836411 , 0.78567386, 0.6354318 ,\n",
       "       0.53772336, 0.9543252 , 0.95500284, 0.9461102 , 0.8219461 ,\n",
       "       0.45179316, 0.86706465, 0.9247909 , 1.0417749 , 0.9287476 ,\n",
       "       0.6299081 , 0.63640034, 1.1421303 , 1.1596866 , 1.104492  ,\n",
       "       1.523519  , 1.2779826 , 1.1187562 , 0.9509142 , 0.6946317 ,\n",
       "       0.43775293, 1.8377604 , 1.7060714 , 1.4577321 , 1.1865503 ,\n",
       "       0.8063267 , 0.9023357 , 2.4548678 , 1.9295872 , 1.5575138 ,\n",
       "       1.2764499 , 2.630885  , 2.0274146 , 1.7164342 , 1.2034322 ,\n",
       "       2.7603424 , 1.973675  , 1.3827966 , 1.0632343 , 0.7378168 ,\n",
       "       0.7264999 , 0.47979254, 2.6444514 , 1.8167125 , 1.2998445 ,\n",
       "       0.9866424 , 0.84460247, 0.7777054 , 2.294515  , 1.4828767 ,\n",
       "       1.1015981 , 0.9955098 , 0.9674776 , 1.723946  , 1.3080404 ,\n",
       "       1.0730662 , 0.9689389 , 1.4431418 , 1.1366916 , 0.98278475,\n",
       "       0.9763905 , 0.8249497 , 0.72700346, 0.5863864 , 0.8414549 ,\n",
       "       0.81807786, 0.770729  , 0.72230715, 0.7531644 , 0.76627874,\n",
       "       0.65566874, 0.70563155, 0.7015361 , 0.84662193, 0.59764796,\n",
       "       0.3291943 , 0.5296665 , 0.6788916 , 0.8098075 , 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].mean_a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03962821, -0.16031033, -0.006051  ,  0.00805688,  0.07023698,\n",
       "       -0.05225641, -0.0346148 ,  0.24869365,  0.21169072,  0.16600877,\n",
       "        0.18427384,  0.16133398,  0.06054109,  0.0586704 ,  0.12116051,\n",
       "        0.06538439,  0.30067533,  0.17690182,  0.13555306, -0.03873003,\n",
       "        0.04424071,  0.10631174,  0.12324637,  0.20491636,  0.38682747,\n",
       "        0.19990784,  0.35613394,  0.398031  ,  0.25766933,  0.4467106 ,\n",
       "        0.21070206,  0.12259886, -0.1298784 ,  0.03226012,  0.21139592,\n",
       "        0.10671306,  0.39461863,  0.73092186,  0.33637   ,  0.11589098,\n",
       "        0.3336376 ,  0.21321559,  0.06850988, -0.03186822,  0.15563929,\n",
       "       -0.07533395,  0.13652086, -0.04618245], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].mean_a1_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sent_word_data = data[0].word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FFD',\n",
       " 'FFD_a1',\n",
       " 'FFD_a1_diff',\n",
       " 'FFD_a2',\n",
       " 'FFD_a2_diff',\n",
       " 'FFD_b1',\n",
       " 'FFD_b1_diff',\n",
       " 'FFD_b2',\n",
       " 'FFD_b2_diff',\n",
       " 'FFD_g1',\n",
       " 'FFD_g1_diff',\n",
       " 'FFD_g2',\n",
       " 'FFD_g2_diff',\n",
       " 'FFD_pupilsize',\n",
       " 'FFD_t1',\n",
       " 'FFD_t1_diff',\n",
       " 'FFD_t2',\n",
       " 'FFD_t2_diff',\n",
       " 'GD',\n",
       " 'GD_a1',\n",
       " 'GD_a1_diff',\n",
       " 'GD_a2',\n",
       " 'GD_a2_diff',\n",
       " 'GD_b1',\n",
       " 'GD_b1_diff',\n",
       " 'GD_b2',\n",
       " 'GD_b2_diff',\n",
       " 'GD_g1',\n",
       " 'GD_g1_diff',\n",
       " 'GD_g2',\n",
       " 'GD_g2_diff',\n",
       " 'GD_pupilsize',\n",
       " 'GD_t1',\n",
       " 'GD_t1_diff',\n",
       " 'GD_t2',\n",
       " 'GD_t2_diff',\n",
       " 'GPT',\n",
       " 'GPT_a1',\n",
       " 'GPT_a1_diff',\n",
       " 'GPT_a2',\n",
       " 'GPT_a2_diff',\n",
       " 'GPT_b1',\n",
       " 'GPT_b1_diff',\n",
       " 'GPT_b2',\n",
       " 'GPT_b2_diff',\n",
       " 'GPT_g1',\n",
       " 'GPT_g1_diff',\n",
       " 'GPT_g2',\n",
       " 'GPT_g2_diff',\n",
       " 'GPT_pupilsize',\n",
       " 'GPT_t1',\n",
       " 'GPT_t1_diff',\n",
       " 'GPT_t2',\n",
       " 'GPT_t2_diff',\n",
       " 'SFD',\n",
       " 'SFD_a1',\n",
       " 'SFD_a1_diff',\n",
       " 'SFD_a2',\n",
       " 'SFD_a2_diff',\n",
       " 'SFD_b1',\n",
       " 'SFD_b1_diff',\n",
       " 'SFD_b2',\n",
       " 'SFD_b2_diff',\n",
       " 'SFD_g1',\n",
       " 'SFD_g1_diff',\n",
       " 'SFD_g2',\n",
       " 'SFD_g2_diff',\n",
       " 'SFD_pupilsize',\n",
       " 'SFD_t1',\n",
       " 'SFD_t1_diff',\n",
       " 'SFD_t2',\n",
       " 'SFD_t2_diff',\n",
       " 'TRT',\n",
       " 'TRT_a1',\n",
       " 'TRT_a1_diff',\n",
       " 'TRT_a2',\n",
       " 'TRT_a2_diff',\n",
       " 'TRT_b1',\n",
       " 'TRT_b1_diff',\n",
       " 'TRT_b2',\n",
       " 'TRT_b2_diff',\n",
       " 'TRT_g1',\n",
       " 'TRT_g1_diff',\n",
       " 'TRT_g2',\n",
       " 'TRT_g2_diff',\n",
       " 'TRT_pupilsize',\n",
       " 'TRT_t1',\n",
       " 'TRT_t1_diff',\n",
       " 'TRT_t2',\n",
       " 'TRT_t2_diff',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_fieldnames',\n",
       " 'content',\n",
       " 'fixPositions',\n",
       " 'meanPupilSize',\n",
       " 'nFixations',\n",
       " 'rawEEG',\n",
       " 'rawET']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(first_sent_word_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_keys = ['FFD', 'TRT', 'GD', 'GPT', 'SFD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = []\n",
    "for w in first_sent_word_data:\n",
    "    if np.shape(w.FFD_a1)[0] != 0:\n",
    "        mean_vec.append(w.FFD_a1)\n",
    "    else:\n",
    "        mean_vec.append(np.zeros(105, ))\n",
    "    if np.shape(w.TRT_a1)[0] != 0:\n",
    "        mean_vec.append(w.TRT_a1)\n",
    "    else:\n",
    "        mean_vec.append(np.zeros(105,))\n",
    "    if np.shape(w.GD_a1)[0] != 0:\n",
    "        mean_vec.append(w.GD_a1)\n",
    "    else:\n",
    "        mean_vec.append(np.zeros(105,))\n",
    "    if np.shape(w.GPT_a1)[0] != 0:\n",
    "        mean_vec.append(w.GPT_a1)\n",
    "    else:\n",
    "        mean_vec.append(np.zeros(105,))\n",
    "    if np.shape(w.SFD_a1)[0] != 0:\n",
    "        mean_vec.append(w.SFD_a1)\n",
    "    else:\n",
    "        mean_vec.append(np.zeros(105,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_vec = []\n",
    "# for w in first_sent_word_data:\n",
    "#     if np.shape(w.FFD_a1)[0] == 0:\n",
    "#         print(\"FFD\")\n",
    "#         #mean_vec.append(w.FFD_a1)\n",
    "#     if np.shape(w.TRT_a1)[0] == 0:\n",
    "#         print(\"TRT\")\n",
    "#         #mean_vec.append(w.TRT_a1)\n",
    "#     if np.shape(w.GD_a1)[0] == 0:\n",
    "#         print(\"GD\")\n",
    "#         #mean_vec.append(w.GD_a1)\n",
    "#     if np.shape(w.GPT_a1)[0] == 0:\n",
    "#         print(\"GPT\")\n",
    "#         #mean_vec.append(w.GPT_a1)\n",
    "#     if np.shape(w.SFD_a1)[0] == 0:\n",
    "#         print(\"SFD\")\n",
    "#         #mean_vec.append(w.SFD_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(w.FFD_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6054074901356522"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40591857, 0.75719452, 0.76280004, 0.94856644, 1.05752206,\n",
       "       0.50663656, 0.63521439, 0.75372767, 0.82306552, 0.83693457,\n",
       "       0.66437054, 0.70226735, 0.76326489, 0.73722726, 0.6980688 ,\n",
       "       1.00000942, 0.4407219 , 0.66637623, 0.64499789, 0.3702977 ,\n",
       "       0.59544927, 0.66627342, 0.49173701, 0.44956049, 0.3528302 ,\n",
       "       0.31686187, 0.33261576, 0.53838074, 0.46792671, 0.31606403,\n",
       "       0.31704211, 0.40655693, 0.88960081, 0.5740729 , 0.51724094,\n",
       "       0.50712609, 0.60694355, 1.03674746, 1.12922704, 1.0517832 ,\n",
       "       1.27990973, 0.99842197, 0.77063876, 0.57528192, 0.38948461,\n",
       "       0.28921601, 0.96650958, 0.97208166, 0.91678911, 0.79044932,\n",
       "       0.3661375 , 0.45487836, 1.24283755, 0.92326736, 0.95216793,\n",
       "       0.72229791, 1.2043165 , 0.84532601, 1.00261462, 0.60786444,\n",
       "       1.25376236, 0.67564827, 0.56797945, 0.47103262, 0.37136737,\n",
       "       0.44428673, 0.46344185, 1.20341754, 0.74520987, 0.55240291,\n",
       "       0.38696954, 0.60517997, 0.46290782, 1.18297613, 0.69435811,\n",
       "       0.36273643, 0.37610722, 0.51328367, 0.92494327, 0.51553601,\n",
       "       0.3516984 , 0.35401034, 0.69198304, 0.49631569, 0.38699582,\n",
       "       0.47248638, 0.68959188, 1.03180885, 0.77491766, 0.36967185,\n",
       "       0.36207947, 0.76580471, 0.79021621, 0.86759561, 0.39727738,\n",
       "       0.39768994, 0.63512379, 0.81912798, 1.21450365, 0.51734954,\n",
       "       0.27271634, 0.32174256, 0.71172148, 1.06338215, 0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.SFD_a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'a': 2,\n",
       "             'basic': 1,\n",
       "             'beyond': 1,\n",
       "             'care': 1,\n",
       "             'case': 1,\n",
       "             'decency.': 1,\n",
       "             'dictums': 1,\n",
       "             'failing': 1,\n",
       "             'for': 1,\n",
       "             'good': 1,\n",
       "             'human': 1,\n",
       "             'of': 1,\n",
       "             'presents': 1,\n",
       "             'provide': 1,\n",
       "             'reason': 1,\n",
       "             'the': 1,\n",
       "             'to': 2,\n",
       "             'us': 1,\n",
       "             'very': 1,\n",
       "             'while': 1})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'lemma'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-0c3becb41094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"He was falling.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'lemma'"
     ]
    }
   ],
   "source": [
    "nltk.word_tokenize(\"He was falling.\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 'PRP'), ('is', 'VBZ'), ('falling', 'VBG')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['he', 'is', 'falling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fall'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lemmatizer.lemmatize('falling', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer.lemmatize??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;9manswers.zip\u001b[0m  \u001b[38;5;27mscripts\u001b[0m/     \u001b[38;5;27mtask1_sr\u001b[0m/     \u001b[38;5;9mtask2_NR.zip\u001b[0m   \u001b[38;5;9mtask_materials.zip\u001b[0m\r\n",
      "nohup.out    \u001b[38;5;9mscripts.zip\u001b[0m  \u001b[38;5;9mtask1_SR.zip\u001b[0m  \u001b[38;5;9mtask3_TSR.zip\u001b[0m  wget-log\r\n"
     ]
    }
   ],
   "source": [
    "ls $dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip ~/ZuCo_dataset/task2_NR.zip -d task2_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip ~/ZuCo_dataset/task3_TSR.zip -d task3_tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relations_normal_reading_control_questions.csv  \u001b[0m\u001b[38;5;27mZAB\u001b[0m/  \u001b[38;5;27mZGW\u001b[0m/  \u001b[38;5;27mZJS\u001b[0m/  \u001b[38;5;27mZKW\u001b[0m/\r\n",
      "relations_normal_reading.csv                    \u001b[38;5;27mZDM\u001b[0m/  \u001b[38;5;27mZJM\u001b[0m/  \u001b[38;5;27mZKB\u001b[0m/  \u001b[38;5;27mZMG\u001b[0m/\r\n",
      "sentencesNR.mat                                 \u001b[38;5;27mZDN\u001b[0m/  \u001b[38;5;27mZJN\u001b[0m/  \u001b[38;5;27mZKH\u001b[0m/  \u001b[38;5;27mZPH\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls task2_nr/Preprocessed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open ‘relations_normal_reading.csv’ for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head relations_normal_reading.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/singh_shruti/workspace/aiproj'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_DataExploration.ipynb  nohup.out  \u001b[0m\u001b[38;5;27mscripts\u001b[0m/  utils_ZuCo.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG processing imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_ZuCo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resultsZDN_SR.mat',\n",
       " 'resultsZKH_SR.mat',\n",
       " 'resultsZKB_SR.mat',\n",
       " 'resultsZJN_SR.mat',\n",
       " 'resultsZDM_SR.mat',\n",
       " 'resultsZKW_SR.mat',\n",
       " 'resultsZPH_SR.mat',\n",
       " 'resultsZMG_SR.mat',\n",
       " 'resultsZAB_SR.mat',\n",
       " 'resultsZJM_SR.mat',\n",
       " 'resultsZJS_SR.mat',\n",
       " 'resultsZGW_SR.mat']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultsZKH_SR.mat\n",
      "resultsZKB_SR.mat\n",
      "resultsZJN_SR.mat\n",
      "resultsZDM_SR.mat\n",
      "resultsZKW_SR.mat\n",
      "resultsZPH_SR.mat\n",
      "resultsZMG_SR.mat\n",
      "resultsZAB_SR.mat\n",
      "resultsZJM_SR.mat\n",
      "resultsZJS_SR.mat\n",
      "resultsZGW_SR.mat\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(path)[1:]:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-389a94ad7a32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "files, len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZAB_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZDM_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZGW_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZJM_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZJN_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZJS_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZKB_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZKH_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZKW_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZMG_SR.mat',\n",
       " '/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZPH_SR.mat']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatransform_t1 = DataTransformer('task1', level='word', scaling='min-max', fillna='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(datatransform_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbjs_t1 = [datatransform_t1(i) for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.loadmat(\"/home/singh_shruti/ZuCo_dataset/task1_sr/Matlab files/resultsZAB_SR.mat\", squeeze_me=True, struct_as_record=False)['sentenceData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content', 'rawData', 'mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2', 'mean_t1_sec', 'mean_t2_sec', 'mean_a1_sec', 'mean_a2_sec', 'mean_b1_sec', 'mean_b2_sec', 'mean_g1_sec', 'mean_g2_sec', 'mean_t1_diff', 'mean_t2_diff', 'mean_a1_diff', 'mean_a2_diff', 'mean_b1_diff', 'mean_b2_diff', 'mean_g1_diff', 'mean_g2_diff', 'mean_t1_diff_sec', 'mean_t2_diff_sec', 'mean_a1_diff_sec', 'mean_a2_diff_sec', 'mean_b1_diff_sec', 'mean_b2_diff_sec', 'mean_g1_diff_sec', 'mean_g2_diff_sec', 'word', 'omissionRate', 'allFixations', 'wordbounds', 'answer_mean_t1', 'answer_mean_t2', 'answer_mean_a1', 'answer_mean_a2', 'answer_mean_b1', 'answer_mean_b2', 'answer_mean_g1', 'answer_mean_g2', 'answer_mean_t1_diff', 'answer_mean_t2_diff', 'answer_mean_a1_diff', 'answer_mean_a2_diff', 'answer_mean_b1_diff', 'answer_mean_b2_diff', 'answer_mean_g1_diff', 'answer_mean_g2_diff']\n"
     ]
    }
   ],
   "source": [
    "# get all field names for sentence data\n",
    "print(data[0]._fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presents a good case while failing to provide a reason for us to care beyond the very basic dictums of human decency.\n"
     ]
    }
   ],
   "source": [
    "# example: print sentence\n",
    "print(data[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_fieldnames',\n",
       " 'allFixations',\n",
       " 'answer_mean_a1',\n",
       " 'answer_mean_a1_diff',\n",
       " 'answer_mean_a2',\n",
       " 'answer_mean_a2_diff',\n",
       " 'answer_mean_b1',\n",
       " 'answer_mean_b1_diff',\n",
       " 'answer_mean_b2',\n",
       " 'answer_mean_b2_diff',\n",
       " 'answer_mean_g1',\n",
       " 'answer_mean_g1_diff',\n",
       " 'answer_mean_g2',\n",
       " 'answer_mean_g2_diff',\n",
       " 'answer_mean_t1',\n",
       " 'answer_mean_t1_diff',\n",
       " 'answer_mean_t2',\n",
       " 'answer_mean_t2_diff',\n",
       " 'content',\n",
       " 'mean_a1',\n",
       " 'mean_a1_diff',\n",
       " 'mean_a1_diff_sec',\n",
       " 'mean_a1_sec',\n",
       " 'mean_a2',\n",
       " 'mean_a2_diff',\n",
       " 'mean_a2_diff_sec',\n",
       " 'mean_a2_sec',\n",
       " 'mean_b1',\n",
       " 'mean_b1_diff',\n",
       " 'mean_b1_diff_sec',\n",
       " 'mean_b1_sec',\n",
       " 'mean_b2',\n",
       " 'mean_b2_diff',\n",
       " 'mean_b2_diff_sec',\n",
       " 'mean_b2_sec',\n",
       " 'mean_g1',\n",
       " 'mean_g1_diff',\n",
       " 'mean_g1_diff_sec',\n",
       " 'mean_g1_sec',\n",
       " 'mean_g2',\n",
       " 'mean_g2_diff',\n",
       " 'mean_g2_diff_sec',\n",
       " 'mean_g2_sec',\n",
       " 'mean_t1',\n",
       " 'mean_t1_diff',\n",
       " 'mean_t1_diff_sec',\n",
       " 'mean_t1_sec',\n",
       " 'mean_t2',\n",
       " 'mean_t2_diff',\n",
       " 'mean_t2_diff_sec',\n",
       " 'mean_t2_sec',\n",
       " 'omissionRate',\n",
       " 'rawData',\n",
       " 'word',\n",
       " 'wordbounds']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content',\n",
       " 'rawData',\n",
       " 'mean_t1',\n",
       " 'mean_t2',\n",
       " 'mean_a1',\n",
       " 'mean_a2',\n",
       " 'mean_b1',\n",
       " 'mean_b2',\n",
       " 'mean_g1',\n",
       " 'mean_g2',\n",
       " 'mean_t1_sec',\n",
       " 'mean_t2_sec',\n",
       " 'mean_a1_sec',\n",
       " 'mean_a2_sec',\n",
       " 'mean_b1_sec',\n",
       " 'mean_b2_sec',\n",
       " 'mean_g1_sec',\n",
       " 'mean_g2_sec',\n",
       " 'mean_t1_diff',\n",
       " 'mean_t2_diff',\n",
       " 'mean_a1_diff',\n",
       " 'mean_a2_diff',\n",
       " 'mean_b1_diff',\n",
       " 'mean_b2_diff',\n",
       " 'mean_g1_diff',\n",
       " 'mean_g2_diff',\n",
       " 'mean_t1_diff_sec',\n",
       " 'mean_t2_diff_sec',\n",
       " 'mean_a1_diff_sec',\n",
       " 'mean_a2_diff_sec',\n",
       " 'mean_b1_diff_sec',\n",
       " 'mean_b2_diff_sec',\n",
       " 'mean_g1_diff_sec',\n",
       " 'mean_g2_diff_sec',\n",
       " 'word',\n",
       " 'omissionRate',\n",
       " 'allFixations',\n",
       " 'wordbounds',\n",
       " 'answer_mean_t1',\n",
       " 'answer_mean_t2',\n",
       " 'answer_mean_a1',\n",
       " 'answer_mean_a2',\n",
       " 'answer_mean_b1',\n",
       " 'answer_mean_b2',\n",
       " 'answer_mean_g1',\n",
       " 'answer_mean_g2',\n",
       " 'answer_mean_t1_diff',\n",
       " 'answer_mean_t2_diff',\n",
       " 'answer_mean_a1_diff',\n",
       " 'answer_mean_a2_diff',\n",
       " 'answer_mean_b1_diff',\n",
       " 'answer_mean_b2_diff',\n",
       " 'answer_mean_g1_diff',\n",
       " 'answer_mean_g2_diff']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]._fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896f98>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f8968d0>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896898>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896908>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896ac8>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896978>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896860>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896a20>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896d30>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc16f896e10>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbf588>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbf2b0>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbf320>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbf358>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbfb70>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbfeb8>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbfe10>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbfdd8>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbfe48>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbfef0>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbf940>,\n",
       "       <scipy.io.matlab.mio5_params.mat_struct object at 0x7fc177dbff28>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word level data\n",
    "word_data = data[0].word\n",
    "word_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content', 'fixPositions', 'nFixations', 'meanPupilSize', 'rawEEG', 'rawET', 'FFD', 'FFD_pupilsize', 'FFD_t1', 'FFD_t2', 'FFD_a1', 'FFD_a2', 'FFD_b1', 'FFD_b2', 'FFD_g1', 'FFD_g2', 'FFD_t1_diff', 'FFD_t2_diff', 'FFD_a1_diff', 'FFD_a2_diff', 'FFD_b1_diff', 'FFD_b2_diff', 'FFD_g1_diff', 'FFD_g2_diff', 'TRT', 'TRT_pupilsize', 'TRT_t1', 'TRT_t2', 'TRT_a1', 'TRT_a2', 'TRT_b1', 'TRT_b2', 'TRT_g1', 'TRT_g2', 'TRT_t1_diff', 'TRT_t2_diff', 'TRT_a1_diff', 'TRT_a2_diff', 'TRT_b1_diff', 'TRT_b2_diff', 'TRT_g1_diff', 'TRT_g2_diff', 'GD', 'GD_pupilsize', 'GD_t1', 'GD_t2', 'GD_a1', 'GD_a2', 'GD_b1', 'GD_b2', 'GD_g1', 'GD_g2', 'GD_t1_diff', 'GD_t2_diff', 'GD_a1_diff', 'GD_a2_diff', 'GD_b1_diff', 'GD_b2_diff', 'GD_g1_diff', 'GD_g2_diff', 'GPT', 'GPT_pupilsize', 'GPT_t1', 'GPT_t2', 'GPT_a1', 'GPT_a2', 'GPT_b1', 'GPT_b2', 'GPT_g1', 'GPT_g2', 'GPT_t1_diff', 'GPT_t2_diff', 'GPT_a1_diff', 'GPT_a2_diff', 'GPT_b1_diff', 'GPT_b2_diff', 'GPT_g1_diff', 'GPT_g2_diff', 'SFD', 'SFD_pupilsize', 'SFD_t1', 'SFD_t2', 'SFD_a1', 'SFD_a2', 'SFD_b1', 'SFD_b2', 'SFD_g1', 'SFD_g2', 'SFD_t1_diff', 'SFD_t2_diff', 'SFD_a1_diff', 'SFD_a2_diff', 'SFD_b1_diff', 'SFD_b2_diff', 'SFD_g1_diff', 'SFD_g2_diff']\n"
     ]
    }
   ],
   "source": [
    "# get names of all word features\n",
    "# index of the array `word_data` is the number of the word\n",
    "print(word_data[0]._fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presents\n"
     ]
    }
   ],
   "source": [
    "# example: get first word\n",
    "print(word_data[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# example: get number of fixations of first word\n",
    "print(word_data[0].nFixations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (105,))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_data[0].FFD_t2), word_data[0].FFD_t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " (105,),\n",
       " array([0.19429664, 0.17923741, 0.36307213, 0.50747943, 0.62206709,\n",
       "        0.51871073, 0.42868289, 0.06850591, 0.28140983, 0.57861644,\n",
       "        1.08024967, 0.36859021, 0.36467823, 0.41722685, 1.14768839,\n",
       "        0.55932534, 0.4871715 , 0.79681689, 0.51210332, 0.40454227,\n",
       "        0.55180544, 0.43953407, 0.75510144, 0.38622764, 0.43004686,\n",
       "        0.29673383, 0.3575944 , 0.36961138, 0.3506383 , 0.85081506,\n",
       "        1.26278675, 0.41491231, 0.3718234 , 0.45663175, 0.42179471,\n",
       "        1.03561676, 0.85461956, 0.43418464, 0.46566522, 0.33808869,\n",
       "        0.49680769, 0.46951395, 0.50899029, 0.15184164, 1.6930244 ,\n",
       "        0.76735342, 0.57302761, 0.94475245, 0.7187323 , 1.07659662,\n",
       "        0.72896671, 1.66536224, 1.39709103, 1.28687668, 1.10441923,\n",
       "        1.43177247, 1.32517946, 1.66541123, 1.60669196, 1.8083328 ,\n",
       "        1.39522731, 1.99193358, 1.38413417, 1.54831302, 1.34435618,\n",
       "        1.0585711 , 0.49228552, 1.85182977, 1.85807848, 1.41647136,\n",
       "        1.35392964, 1.03962433, 0.85793865, 2.1952467 , 2.17580271,\n",
       "        2.02598214, 1.63932216, 1.00376701, 1.78744721, 1.96237218,\n",
       "        1.51004064, 1.01614249, 1.20013535, 1.12757885, 0.83896005,\n",
       "        0.99863309, 0.65768403, 0.33150849, 0.16545779, 0.56242204,\n",
       "        1.09004402, 0.59104663, 0.56140357, 0.38477388, 0.60919583,\n",
       "        0.58260262, 0.59866726, 0.35624093, 0.37161309, 0.18472035,\n",
       "        0.93358988, 0.49549541, 0.34883159, 0.24064931, 0.        ]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_data[0].FFD_t1), word_data[0].FFD_t1.shape, word_data[0].FFD_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_features_list = ['FFD_t1', 'FFD_t2', 'FFD_a1', 'FFD_a2', 'FFD_b1', 'FFD_b2', \n",
    "                     'FFD_g1', 'FFD_g2', 'TRT_t1', 'TRT_t2', 'TRT_a1', 'TRT_a2', \n",
    "                     'TRT_b1', 'TRT_b2', 'TRT_g1', 'TRT_g2', 'GD_t1', 'GD_t2', \n",
    "                     'GD_a1', 'GD_a2', 'GD_b1', 'GD_b2', 'GD_g1', 'GD_g2', 'GPT_t1', \n",
    "                     'GPT_t2', 'GPT_a1', 'GPT_a2', 'GPT_b1', 'GPT_b2', 'GPT_g1', \n",
    "                     'GPT_g2',  'SFD_t1', 'SFD_t2', 'SFD_a1', 'SFD_a2', 'SFD_b1', \n",
    "                     'SFD_b2', 'SFD_g1', 'SFD_g2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eeg_features_list:\n",
    "    if not i in word_data[0]._fieldnames:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'mat_struct' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-43ce602026ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meeg_features_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0marr_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'mat_struct' has no len()"
     ]
    }
   ],
   "source": [
    "arr_sizes = []\n",
    "\n",
    "for i in eeg_features_list:\n",
    "    arr_sizes.append(len(word_data[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FFD',\n",
       " 'FFD_a1',\n",
       " 'FFD_a1_diff',\n",
       " 'FFD_a2',\n",
       " 'FFD_a2_diff',\n",
       " 'FFD_b1',\n",
       " 'FFD_b1_diff',\n",
       " 'FFD_b2',\n",
       " 'FFD_b2_diff',\n",
       " 'FFD_g1',\n",
       " 'FFD_g1_diff',\n",
       " 'FFD_g2',\n",
       " 'FFD_g2_diff',\n",
       " 'FFD_pupilsize',\n",
       " 'FFD_t1',\n",
       " 'FFD_t1_diff',\n",
       " 'FFD_t2',\n",
       " 'FFD_t2_diff',\n",
       " 'GD',\n",
       " 'GD_a1',\n",
       " 'GD_a1_diff',\n",
       " 'GD_a2',\n",
       " 'GD_a2_diff',\n",
       " 'GD_b1',\n",
       " 'GD_b1_diff',\n",
       " 'GD_b2',\n",
       " 'GD_b2_diff',\n",
       " 'GD_g1',\n",
       " 'GD_g1_diff',\n",
       " 'GD_g2',\n",
       " 'GD_g2_diff',\n",
       " 'GD_pupilsize',\n",
       " 'GD_t1',\n",
       " 'GD_t1_diff',\n",
       " 'GD_t2',\n",
       " 'GD_t2_diff',\n",
       " 'GPT',\n",
       " 'GPT_a1',\n",
       " 'GPT_a1_diff',\n",
       " 'GPT_a2',\n",
       " 'GPT_a2_diff',\n",
       " 'GPT_b1',\n",
       " 'GPT_b1_diff',\n",
       " 'GPT_b2',\n",
       " 'GPT_b2_diff',\n",
       " 'GPT_g1',\n",
       " 'GPT_g1_diff',\n",
       " 'GPT_g2',\n",
       " 'GPT_g2_diff',\n",
       " 'GPT_pupilsize',\n",
       " 'GPT_t1',\n",
       " 'GPT_t1_diff',\n",
       " 'GPT_t2',\n",
       " 'GPT_t2_diff',\n",
       " 'SFD',\n",
       " 'SFD_a1',\n",
       " 'SFD_a1_diff',\n",
       " 'SFD_a2',\n",
       " 'SFD_a2_diff',\n",
       " 'SFD_b1',\n",
       " 'SFD_b1_diff',\n",
       " 'SFD_b2',\n",
       " 'SFD_b2_diff',\n",
       " 'SFD_g1',\n",
       " 'SFD_g1_diff',\n",
       " 'SFD_g2',\n",
       " 'SFD_g2_diff',\n",
       " 'SFD_pupilsize',\n",
       " 'SFD_t1',\n",
       " 'SFD_t1_diff',\n",
       " 'SFD_t2',\n",
       " 'SFD_t2_diff',\n",
       " 'TRT',\n",
       " 'TRT_a1',\n",
       " 'TRT_a1_diff',\n",
       " 'TRT_a2',\n",
       " 'TRT_a2_diff',\n",
       " 'TRT_b1',\n",
       " 'TRT_b1_diff',\n",
       " 'TRT_b2',\n",
       " 'TRT_b2_diff',\n",
       " 'TRT_g1',\n",
       " 'TRT_g1_diff',\n",
       " 'TRT_g2',\n",
       " 'TRT_g2_diff',\n",
       " 'TRT_pupilsize',\n",
       " 'TRT_t1',\n",
       " 'TRT_t1_diff',\n",
       " 'TRT_t2',\n",
       " 'TRT_t2_diff',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_fieldnames',\n",
       " 'content',\n",
       " 'fixPositions',\n",
       " 'meanPupilSize',\n",
       " 'nFixations',\n",
       " 'rawEEG',\n",
       " 'rawET']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(word_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64),\n",
       " array([0.7923798 , 0.63489175, 1.02781081, 0.80003172, 0.64115089,\n",
       "        0.32353818, 0.47877821, 0.7482419 , 1.02459919, 0.66422927,\n",
       "        0.54948336, 0.51821971, 0.72873878, 0.63881034, 0.5773499 ,\n",
       "        0.71563071, 0.35449752, 0.59358221, 0.59261787, 0.43347245,\n",
       "        0.60748667, 0.65205139, 0.56229717, 0.48488885, 0.34160981,\n",
       "        0.45462072, 0.71885067, 0.6506626 , 0.51853442, 0.39688364,\n",
       "        0.19659023, 0.7033326 , 0.81556404, 0.4577812 , 0.44225255,\n",
       "        0.5253005 , 0.31454113, 0.66364211, 1.13975155, 0.66868407,\n",
       "        0.80140257, 0.88212639, 0.4877941 , 0.31965712, 0.27589515,\n",
       "        0.23692214, 0.85550123, 0.76653475, 0.65327018, 0.47429478,\n",
       "        0.37908867, 0.58112049, 0.91268718, 0.74974769, 0.78024673,\n",
       "        0.68926531, 0.85103428, 0.7415393 , 0.81330562, 0.70207113,\n",
       "        0.81092423, 0.74885523, 0.76991349, 0.73557526, 0.57275552,\n",
       "        0.50937349, 0.37304649, 0.70928764, 0.68744558, 0.78911626,\n",
       "        0.73298335, 0.63536835, 0.67884582, 0.59449017, 0.66116416,\n",
       "        0.69341367, 0.7834518 , 0.82645983, 0.61128545, 0.68239504,\n",
       "        0.82404047, 0.79791665, 0.73449135, 0.7407372 , 0.8802045 ,\n",
       "        0.75502157, 0.63072205, 0.60611123, 0.44690111, 0.69668776,\n",
       "        0.63880605, 0.59332705, 0.62591469, 0.63241702, 0.65727615,\n",
       "        0.60872996, 0.59088653, 0.64437819, 0.9020533 , 0.4326109 ,\n",
       "        0.31455421, 0.54968488, 0.61136162, 0.73343289, 0.        ]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_data[0].SFD_g2, word_data[0].FFD_g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FFD',\n",
       " 'FFD_a1',\n",
       " 'FFD_a1_diff',\n",
       " 'FFD_a2',\n",
       " 'FFD_a2_diff',\n",
       " 'FFD_b1',\n",
       " 'FFD_b1_diff',\n",
       " 'FFD_b2',\n",
       " 'FFD_b2_diff',\n",
       " 'FFD_g1',\n",
       " 'FFD_g1_diff',\n",
       " 'FFD_g2',\n",
       " 'FFD_g2_diff',\n",
       " 'FFD_pupilsize',\n",
       " 'FFD_t1',\n",
       " 'FFD_t1_diff',\n",
       " 'FFD_t2',\n",
       " 'FFD_t2_diff',\n",
       " 'GD',\n",
       " 'GD_a1',\n",
       " 'GD_a1_diff',\n",
       " 'GD_a2',\n",
       " 'GD_a2_diff',\n",
       " 'GD_b1',\n",
       " 'GD_b1_diff',\n",
       " 'GD_b2',\n",
       " 'GD_b2_diff',\n",
       " 'GD_g1',\n",
       " 'GD_g1_diff',\n",
       " 'GD_g2',\n",
       " 'GD_g2_diff',\n",
       " 'GD_pupilsize',\n",
       " 'GD_t1',\n",
       " 'GD_t1_diff',\n",
       " 'GD_t2',\n",
       " 'GD_t2_diff',\n",
       " 'GPT',\n",
       " 'GPT_a1',\n",
       " 'GPT_a1_diff',\n",
       " 'GPT_a2',\n",
       " 'GPT_a2_diff',\n",
       " 'GPT_b1',\n",
       " 'GPT_b1_diff',\n",
       " 'GPT_b2',\n",
       " 'GPT_b2_diff',\n",
       " 'GPT_g1',\n",
       " 'GPT_g1_diff',\n",
       " 'GPT_g2',\n",
       " 'GPT_g2_diff',\n",
       " 'GPT_pupilsize',\n",
       " 'GPT_t1',\n",
       " 'GPT_t1_diff',\n",
       " 'GPT_t2',\n",
       " 'GPT_t2_diff',\n",
       " 'SFD',\n",
       " 'SFD_a1',\n",
       " 'SFD_a1_diff',\n",
       " 'SFD_a2',\n",
       " 'SFD_a2_diff',\n",
       " 'SFD_b1',\n",
       " 'SFD_b1_diff',\n",
       " 'SFD_b2',\n",
       " 'SFD_b2_diff',\n",
       " 'SFD_g1',\n",
       " 'SFD_g1_diff',\n",
       " 'SFD_g2',\n",
       " 'SFD_g2_diff',\n",
       " 'SFD_pupilsize',\n",
       " 'SFD_t1',\n",
       " 'SFD_t1_diff',\n",
       " 'SFD_t2',\n",
       " 'SFD_t2_diff',\n",
       " 'TRT',\n",
       " 'TRT_a1',\n",
       " 'TRT_a1_diff',\n",
       " 'TRT_a2',\n",
       " 'TRT_a2_diff',\n",
       " 'TRT_b1',\n",
       " 'TRT_b1_diff',\n",
       " 'TRT_b2',\n",
       " 'TRT_b2_diff',\n",
       " 'TRT_g1',\n",
       " 'TRT_g1_diff',\n",
       " 'TRT_g2',\n",
       " 'TRT_g2_diff',\n",
       " 'TRT_pupilsize',\n",
       " 'TRT_t1',\n",
       " 'TRT_t1_diff',\n",
       " 'TRT_t2',\n",
       " 'TRT_t2_diff',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_fieldnames',\n",
       " 'content',\n",
       " 'fixPositions',\n",
       " 'meanPupilSize',\n",
       " 'nFixations',\n",
       " 'rawEEG',\n",
       " 'rawET']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(word_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64),\n",
       " array([0.7923798 , 0.63489175, 1.02781081, 0.80003172, 0.64115089,\n",
       "        0.32353818, 0.47877821, 0.7482419 , 1.02459919, 0.66422927,\n",
       "        0.54948336, 0.51821971, 0.72873878, 0.63881034, 0.5773499 ,\n",
       "        0.71563071, 0.35449752, 0.59358221, 0.59261787, 0.43347245,\n",
       "        0.60748667, 0.65205139, 0.56229717, 0.48488885, 0.34160981,\n",
       "        0.45462072, 0.71885067, 0.6506626 , 0.51853442, 0.39688364,\n",
       "        0.19659023, 0.7033326 , 0.81556404, 0.4577812 , 0.44225255,\n",
       "        0.5253005 , 0.31454113, 0.66364211, 1.13975155, 0.66868407,\n",
       "        0.80140257, 0.88212639, 0.4877941 , 0.31965712, 0.27589515,\n",
       "        0.23692214, 0.85550123, 0.76653475, 0.65327018, 0.47429478,\n",
       "        0.37908867, 0.58112049, 0.91268718, 0.74974769, 0.78024673,\n",
       "        0.68926531, 0.85103428, 0.7415393 , 0.81330562, 0.70207113,\n",
       "        0.81092423, 0.74885523, 0.76991349, 0.73557526, 0.57275552,\n",
       "        0.50937349, 0.37304649, 0.70928764, 0.68744558, 0.78911626,\n",
       "        0.73298335, 0.63536835, 0.67884582, 0.59449017, 0.66116416,\n",
       "        0.69341367, 0.7834518 , 0.82645983, 0.61128545, 0.68239504,\n",
       "        0.82404047, 0.79791665, 0.73449135, 0.7407372 , 0.8802045 ,\n",
       "        0.75502157, 0.63072205, 0.60611123, 0.44690111, 0.69668776,\n",
       "        0.63880605, 0.59332705, 0.62591469, 0.63241702, 0.65727615,\n",
       "        0.60872996, 0.59088653, 0.64437819, 0.9020533 , 0.4326109 ,\n",
       "        0.31455421, 0.54968488, 0.61136162, 0.73343289, 0.        ]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_data[0].__dict__['SFD_g2'], word_data[0].__dict__['FFD_g2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
